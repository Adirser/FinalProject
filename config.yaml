datageneration:
  apply_example_scaling: true
  apply_feature_scaling: true
  attribute_discriminator_beta1: 0.5
  attribute_discriminator_learning_rate: 0.001
  attribute_gradient_penalty_coef: 10.0
  attribute_loss_coef: 1.0
  attribute_noise_dim: 10
  attribute_num_layers: 3
  attribute_num_units: 100
  batch_size: 1024
  binary_encoder_cutoff: 150
  discriminator_beta1: 0.5
  discriminator_learning_rate: 0.001
  discriminator_rounds: 1
  epochs: 20
  feature_noise_dim: 10
  feature_num_layers: 1
  feature_num_units: 100
  forget_bias: false
  generate_n_sample: 2997
  generator_beta1: 0.5
  generator_learning_rate: 0.001
  generator_rounds: 1
  gradient_penalty_coef: 10.0
  max_sequence_len: 8
  mixed_precision_training: false
  normalization: false
  percentage_of_original_data: 0.9
  sample_length: 8
  use_attribute_discriminator: true
experiment_params:
  dataset_name: PenDigits
  experiment_index: 1
  num_classes: 10
  num_features: 2
  root_path: C:\Users\nati\Desktop\Implementations\FinalProject
  sequence_length: 8
finetuning:
  batch_size: 27
  criterion: Crossentropy
  epochs: 10
  learning_rate: 0.001
  model_type: inceptionTime
  optimizer: Adam
  patience: 5
  shuffle: true
preprocessing:
  split_ratio: 0.8
pretraining:
  batch_size: 27
  criterion: Crossentropy
  dropout: 0.1
  epochs: 10
  hidden_size: 'Null'
  learning_rate: 0.001
  model_type: inceptionTime
  models_list:
  - LSTM
  - GRU
  multiple_experiments: true
  num_layers_layers_stacked: 'Null'
  num_layers_stacked: 3
  optimizer: Adam
  patience: 5
  save_each_epoch: true
