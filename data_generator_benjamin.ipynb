{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nati\\Desktop\\Implementations\\ImplementationsVenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "# import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from gretel_synthetics.timeseries_dgan.dgan import DGAN\n",
    "from gretel_synthetics.timeseries_dgan.config import DGANConfig,OutputType\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sktime.datasets import load_from_ucr_tsv_to_dataframe\n",
    "from sktime.datasets import load_from_tsfile\n",
    "import neptune.new as neptune\n",
    "import datetime\n",
    "import uuid\n",
    "import pickle as pkl\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from InceptionTime import InceptionBlock,Inception,Reshape,Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing steps:\n",
    "# 1. reading the data\n",
    "# 2. expanding dim \n",
    "# 3. convert target to numbers\n",
    "# 4. generate synthetic data. with control of the amount of original data that the generator model uses.\n",
    "# 5. save the generated data in folder structure \n",
    "X_train,y_train = load_from_tsfile(r\"C:\\Users\\nati\\Desktop\\Implementations\\FinalProject\\Datasets\\BasicMotions\\BasicMotions_TRAIN.ts\")\n",
    "X_test,y_test = load_from_tsfile(r\"C:\\Users\\nati\\Desktop\\Implementations\\FinalProject\\Datasets\\BasicMotions\\BasicMotions_TEST.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dgan(df:pd.DataFrame,sequence_length:int):\n",
    "    df = df.copy(deep=True)\n",
    "    data = []\n",
    "    for row in df.iterrows():\n",
    "        for col in df.columns:\n",
    "            data.append([row[1][col]])\n",
    "    data = np.array(data)\n",
    "    data = data.reshape((df.shape[0], sequence_length, df.shape[1]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_dgan(X_train,100)\n",
    "X_test= preprocess_dgan(X_test,100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):    \n",
    "    def __init__(self, X, y, transform=None, trarget_transform=None):\n",
    "        self.X = X \n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        self.target_transform = trarget_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "        return torch.tensor(X), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=31, hidden_dim=256, num_layers=1, output_dim=5, dropout=0):\n",
    "        '''\n",
    "        input_dim = number of features at each time step \n",
    "        hidden_dim = number of features produced by each LSTM cell (in each layer)\n",
    "        num_layers = number of LSTM layers\n",
    "        output_dim = number of classes (number of activities)\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, \n",
    "                            num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        _, (h_n, c_n) = self.lstm(X)  # (h_0, c_0) default to zeros\n",
    "        out = self.fc(h_n[-1,:,:])\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRU_Classifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=x.device)\n",
    "        out, _ = self.gru(x, h0.detach())\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "def split_dataset_by_label(X, y):\n",
    "    splits = {}\n",
    "    unique_labels = np.unique(y)\n",
    "    for label in unique_labels:\n",
    "        splits[label] = {'X': np.array(X[y == label]), 'y': np.array(y[y == label])}\n",
    "    return splits\n",
    "\n",
    "def get_divisor(num:int):\n",
    "    divisors = []\n",
    "    for i in range(1, num + 1):\n",
    "        if num % i == 0:\n",
    "            divisors.append(i)\n",
    "    return divisors\n",
    "DGAN_param = {  'epochs': 1,\n",
    "                'attribute_noise_dim': 10,\n",
    "                'feature_noise_dim': 10, \n",
    "                'attribute_num_layers': 3, \n",
    "                'attribute_num_units': 100, \n",
    "                'feature_num_layers':  1, \n",
    "                'feature_num_units':100, \n",
    "                'use_attribute_discriminator': True, \n",
    "                'normalization': False, \n",
    "                'apply_feature_scaling': True, \n",
    "                'apply_example_scaling': True, \n",
    "                'binary_encoder_cutoff': 150, \n",
    "                'forget_bias': False, \n",
    "                'gradient_penalty_coef': 10.0, \n",
    "                'attribute_gradient_penalty_coef':10.0, \n",
    "                'attribute_loss_coef': 1.0, \n",
    "                'generator_learning_rate':  0.001, \n",
    "                'generator_beta1':  0.5, \n",
    "                'discriminator_learning_rate': 0.001, \n",
    "                'discriminator_beta1': 0.5, \n",
    "                'attribute_discriminator_learning_rate':  0.001, \n",
    "                'attribute_discriminator_beta1': 0.5, \n",
    "                'batch_size':  1024, \n",
    "                'discriminator_rounds': 1, \n",
    "                'generator_rounds': 1,\n",
    "                'mixed_precision_training': False}\n",
    "def train_dgan(data:np.ndarray, DGAN_param:dict, Experiment_param:dict):\n",
    "    run = neptune.init_run(\n",
    "    project=\"astarteam/FinalProject\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhMDI5YzIxMy00NjE1LTQ2MDUtOTk3NS1jNDJhMjIzZDE0NDMifQ==\",\n",
    "    )  # your credentialscredentials\n",
    "\n",
    "    run['Experiment_param'] = Experiment_param\n",
    "    run[\"DGAN_param\"] = DGAN_param\n",
    "\n",
    "    model = DGAN(DGANConfig(\n",
    "        max_sequence_len=data.shape[1],\n",
    "        sample_len=random.choice(get_divisor(data.shape[1])[-3:]), \n",
    "        batch_size=min(1000, data.shape[0]),\n",
    "        apply_feature_scaling=DGAN_param['apply_feature_scaling'],\n",
    "        apply_example_scaling=DGAN_param['apply_example_scaling'],\n",
    "        use_attribute_discriminator=DGAN_param['use_attribute_discriminator'],\n",
    "        generator_learning_rate=DGAN_param['generator_learning_rate'],\n",
    "        discriminator_learning_rate=DGAN_param['discriminator_learning_rate'],\n",
    "        epochs=DGAN_param['epochs'],\n",
    "        gradient_penalty_coef = DGAN_param['gradient_penalty_coef'],\n",
    "    ))\n",
    "\n",
    "    model.train_numpy(\n",
    "        data,\n",
    "        feature_types=[OutputType.CONTINUOUS] * data.shape[2],\n",
    "    )\n",
    "    time.sleep(2)\n",
    "    run.stop()\n",
    "    return model\n",
    "\n",
    "def train_generator_per_label(splitted_data:pd.DataFrame, DGAN_param:dict, Experiment_param:dict):\n",
    "    models = {}\n",
    "    for label in splitted_data.keys():\n",
    "        print(f\"Training generator for label {label}\")\n",
    "        X = splitted_data[label]['X']\n",
    "        DGAN_param['label'] = label\n",
    "        model = train_dgan(X, DGAN_param, Experiment_param)\n",
    "        models[label] = model\n",
    "    return models\n",
    "\n",
    "def generate_data_per_label(models, num_samples, Experiment_param):\n",
    "    generated_data = {}\n",
    "    for label in models.keys():\n",
    "        print(f\"Generating data for label {label}\")\n",
    "        generated_data[label] = models[label].generate_numpy(num_samples)[1]\n",
    "    concatenated_data = {'X':np.concatenate([generated_data[label] for label in generated_data.keys()]),\n",
    "                'y':np.concatenate([np.array([label]*num_samples) for label in generated_data.keys()])}\n",
    "    np.save(f'''dataset/{Experiment_param['Dataset name']}/{Experiment_param['Experiment_id']}''', concatenated_data)\n",
    "    # df.to_csv(f'''dataset/{DGAN_param['Dataset name']}/{DGAN_param['Experiment_id']}.csv''', index=False)\n",
    "    return generated_data,concatenated_data\n",
    "\n",
    "def create_data_loaders(X,y,n_splits:int = 1, validation_size:float=0.2):\n",
    "    ssf = StratifiedShuffleSplit(n_splits=n_splits, test_size=validation_size)\n",
    "    train_ind, test_ind = next(ssf.split(X,y))\n",
    "    train_dataloader = DataLoader(TimeSeriesDataset(X[train_ind],y[train_ind]),batch_size=20,shuffle=True)\n",
    "    validation_dataloader = DataLoader(TimeSeriesDataset(X[test_ind],y[test_ind]),batch_size=20,shuffle=True)\n",
    "    return train_dataloader, validation_dataloader\n",
    "\n",
    "def map_label_int(y):    \n",
    "    label_to_int = {label: i for i, label in enumerate(np.unique(y))}\n",
    "    int_to_label = {i: label for label, i in label_to_int.items()}\n",
    "    y_int = np.array([label_to_int[label] for label in y])\n",
    "    return label_to_int, int_to_label, y_int\n",
    "\n",
    "def train_loop(data_loader, model,device,loss_fn,optimizer,print_every_n=200):\n",
    "    model.train()\n",
    "    size = len(data_loader.dataset)\n",
    "    num_batches = len(data_loader)\n",
    "    train_loss=0\n",
    "    tp=0\n",
    "    for batch,(X,y) in enumerate(data_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        y = y.to(device)\n",
    "        pred = model(X.float())\n",
    "        # print(f'Preds : {pred.argmax(1)}')\n",
    "        # print(f'GT : {y}')\n",
    "        loss = loss_fn(pred,y)\n",
    "        train_loss += loss\n",
    "        tp += (y==pred.argmax(1)).type(torch.float).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss, current = loss.item(), batch*len(X)\n",
    "        if batch%print_every_n==0:\n",
    "            print(f'loss={loss:.3f}, {current} / {size}')\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_acc = tp/size    \n",
    "    print(f'train accuracy = {train_acc}, val_loss = {train_loss:2f}')\n",
    "    return train_loss,train_acc\n",
    "\n",
    "def validation_loop(data_loader,model,device,loss_fn):\n",
    "    model.eval()\n",
    "    size=len(data_loader.dataset)\n",
    "    num_batches = len(data_loader)\n",
    "    val_loss=0\n",
    "    tp=0\n",
    "    with torch.no_grad():\n",
    "        for X,y in data_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "            pred = model(X.float())\n",
    "            val_loss += loss_fn(pred,y).item()\n",
    "            tp += (y==pred.argmax(1)).type(torch.float).sum().item()\n",
    "        \n",
    "    val_loss /= num_batches\n",
    "    val_acc = tp/size\n",
    "    print(f'validation accuracy = {val_acc}, val_loss = {val_loss:2f}')\n",
    "    return val_loss,val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training generator for label badminton\n",
      "https://app.neptune.ai/astarteam/FinalProject/e/FIN-111\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiprocessing_context option should specify a valid start method in ['spawn'], but got multiprocessing_context='fork'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 35\u001b[0m\n\u001b[0;32m      3\u001b[0m Experiment_param \u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mexperiment state\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mdata generation\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mExperiment_id\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00muuid\u001b[39m.\u001b[39muuid4()\u001b[39m.\u001b[39mhex\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mDataset name\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mBasicMotions\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m# Dataset name most be as generated dataset dir name. it will be used while saving the generated data  \u001b[39;00m\n\u001b[0;32m      6\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39musage of original data\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m80\u001b[39m, }\n\u001b[0;32m      8\u001b[0m DGAN_param \u001b[39m=\u001b[39m {  \u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[0;32m      9\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mattribute_noise_dim\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m,\n\u001b[0;32m     10\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mfeature_noise_dim\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mgenerator_rounds\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[0;32m     33\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mmixed_precision_training\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m}\n\u001b[1;32m---> 35\u001b[0m models \u001b[39m=\u001b[39m train_generator_per_label(split_data, DGAN_param, Experiment_param)\n\u001b[0;32m     36\u001b[0m generated_data,concatenated_data \u001b[39m=\u001b[39m generate_data_per_label(models, \u001b[39m20\u001b[39m, DGAN_param, Experiment_param)\n\u001b[0;32m     37\u001b[0m label_to_int, int_to_label, concatenated_data[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m map_label_int(concatenated_data[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[14], line 77\u001b[0m, in \u001b[0;36mtrain_generator_per_label\u001b[1;34m(splitted_data, DGAN_param, Experiment_param)\u001b[0m\n\u001b[0;32m     75\u001b[0m     X \u001b[39m=\u001b[39m splitted_data[label][\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     76\u001b[0m     DGAN_param[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m label\n\u001b[1;32m---> 77\u001b[0m     model \u001b[39m=\u001b[39m train_dgan(X, DGAN_param, Experiment_param)\n\u001b[0;32m     78\u001b[0m     models[label] \u001b[39m=\u001b[39m model\n\u001b[0;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m models\n",
      "Cell \u001b[1;32mIn[14], line 63\u001b[0m, in \u001b[0;36mtrain_dgan\u001b[1;34m(data, DGAN_param, Experiment_param)\u001b[0m\n\u001b[0;32m     48\u001b[0m run[\u001b[39m\"\u001b[39m\u001b[39mDGAN_param\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m DGAN_param\n\u001b[0;32m     50\u001b[0m model \u001b[39m=\u001b[39m DGAN(DGANConfig(\n\u001b[0;32m     51\u001b[0m     max_sequence_len\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[0;32m     52\u001b[0m     sample_len\u001b[39m=\u001b[39mrandom\u001b[39m.\u001b[39mchoice(get_divisor(data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m:]), \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     gradient_penalty_coef \u001b[39m=\u001b[39m DGAN_param[\u001b[39m'\u001b[39m\u001b[39mgradient_penalty_coef\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     61\u001b[0m ))\n\u001b[1;32m---> 63\u001b[0m model\u001b[39m.\u001b[39;49mtrain_numpy(\n\u001b[0;32m     64\u001b[0m     data,\n\u001b[0;32m     65\u001b[0m     feature_types\u001b[39m=\u001b[39;49m[OutputType\u001b[39m.\u001b[39;49mCONTINUOUS] \u001b[39m*\u001b[39;49m data\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m],\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     67\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)\n\u001b[0;32m     68\u001b[0m run\u001b[39m.\u001b[39mstop()\n",
      "File \u001b[1;32mc:\\Users\\nati\\Desktop\\Implementations\\ImplementationsVenv\\lib\\site-packages\\gretel_synthetics\\timeseries_dgan\\dgan.py:309\u001b[0m, in \u001b[0;36mDGAN.train_numpy\u001b[1;34m(self, features, feature_types, attributes, attribute_types, progress_callback)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNaN found in internal attributes. \u001b[39m\u001b[39m{\u001b[39;00mNAN_ERROR_MESSAGE\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    303\u001b[0m dataset \u001b[39m=\u001b[39m TensorDataset(\n\u001b[0;32m    304\u001b[0m     torch\u001b[39m.\u001b[39mTensor(internal_attributes),\n\u001b[0;32m    305\u001b[0m     torch\u001b[39m.\u001b[39mTensor(internal_additional_attributes),\n\u001b[0;32m    306\u001b[0m     torch\u001b[39m.\u001b[39mTensor(internal_features),\n\u001b[0;32m    307\u001b[0m )\n\u001b[1;32m--> 309\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(dataset, progress_callback\u001b[39m=\u001b[39;49mprogress_callback)\n",
      "File \u001b[1;32mc:\\Users\\nati\\Desktop\\Implementations\\ImplementationsVenv\\lib\\site-packages\\gretel_synthetics\\timeseries_dgan\\dgan.py:652\u001b[0m, in \u001b[0;36mDGAN._train\u001b[1;34m(self, dataset, progress_callback)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[39m# Our optimization setup does not work on batches of size 1. So if\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[39m# drop_last=False would produce a last batch of size of 1, we use\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[39m# drop_last=True instead.\u001b[39;00m\n\u001b[0;32m    650\u001b[0m drop_last \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataset) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mbatch_size \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 652\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[0;32m    653\u001b[0m     dataset,\n\u001b[0;32m    654\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m    655\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    656\u001b[0m     drop_last\u001b[39m=\u001b[39;49mdrop_last,\n\u001b[0;32m    657\u001b[0m     num_workers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m    658\u001b[0m     prefetch_factor\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,\n\u001b[0;32m    659\u001b[0m     persistent_workers\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    660\u001b[0m     pin_memory\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    661\u001b[0m     multiprocessing_context\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfork\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    662\u001b[0m )\n\u001b[0;32m    664\u001b[0m opt_discriminator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\n\u001b[0;32m    665\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_discriminator\u001b[39m.\u001b[39mparameters(),\n\u001b[0;32m    666\u001b[0m     lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdiscriminator_learning_rate,\n\u001b[0;32m    667\u001b[0m     betas\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdiscriminator_beta1, \u001b[39m0.999\u001b[39m),\n\u001b[0;32m    668\u001b[0m )\n\u001b[0;32m    670\u001b[0m opt_attribute_discriminator \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nati\\Desktop\\Implementations\\ImplementationsVenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:255\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout \u001b[39m=\u001b[39m timeout\n\u001b[0;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworker_init_fn \u001b[39m=\u001b[39m worker_init_fn\n\u001b[1;32m--> 255\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultiprocessing_context \u001b[39m=\u001b[39m multiprocessing_context\n\u001b[0;32m    257\u001b[0m \u001b[39m# Adds forward compatibilities so classic DataLoader can work with DataPipes:\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39m#   _DataPipeSerializationWrapper container makes it easier to serialize without redefining pickler\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, IterDataPipe):\n",
      "File \u001b[1;32mc:\\Users\\nati\\Desktop\\Implementations\\ImplementationsVenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:418\u001b[0m, in \u001b[0;36mDataLoader.__setattr__\u001b[1;34m(self, attr, val)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__initialized \u001b[39mand\u001b[39;00m attr \u001b[39min\u001b[39;00m (\n\u001b[0;32m    414\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbatch_sampler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msampler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdrop_last\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpersistent_workers\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    415\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m attribute should not be set after \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    416\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39minitialized\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(attr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n\u001b[1;32m--> 418\u001b[0m \u001b[39msuper\u001b[39;49m(DataLoader, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(attr, val)\n",
      "File \u001b[1;32mc:\\Users\\nati\\Desktop\\Implementations\\ImplementationsVenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:394\u001b[0m, in \u001b[0;36mDataLoader.multiprocessing_context\u001b[1;34m(self, multiprocessing_context)\u001b[0m\n\u001b[0;32m    392\u001b[0m valid_start_methods \u001b[39m=\u001b[39m multiprocessing\u001b[39m.\u001b[39mget_all_start_methods()\n\u001b[0;32m    393\u001b[0m \u001b[39mif\u001b[39;00m multiprocessing_context \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m valid_start_methods:\n\u001b[1;32m--> 394\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    395\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mmultiprocessing_context option \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    396\u001b[0m          \u001b[39m'\u001b[39m\u001b[39mshould specify a valid start method in \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    397\u001b[0m          \u001b[39m'\u001b[39m\u001b[39mmultiprocessing_context=\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mformat(valid_start_methods, multiprocessing_context))\n\u001b[0;32m    398\u001b[0m \u001b[39m# error: Argument 1 to \"get_context\" has incompatible type \"Union[str, bytes]\"; expected \"str\"  [arg-type]\u001b[39;00m\n\u001b[0;32m    399\u001b[0m multiprocessing_context \u001b[39m=\u001b[39m multiprocessing\u001b[39m.\u001b[39mget_context(multiprocessing_context)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: multiprocessing_context option should specify a valid start method in ['spawn'], but got multiprocessing_context='fork'"
     ]
    }
   ],
   "source": [
    "split_data = split_dataset_by_label(X_train,y_train)\n",
    "# TODO: add params to train generator so we can track the dataset generating process  \n",
    "Experiment_param ={'experiment state':'data generation',\n",
    "                'Experiment_id': f'{datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}_{uuid.uuid4().hex}',\n",
    "                'Dataset name':'BasicMotions', # Dataset name most be as generated dataset dir name. it will be used while saving the generated data  \n",
    "                'usage of original data': 80, }\n",
    "\n",
    "DGAN_param = {  'epochs': 1,\n",
    "                'attribute_noise_dim': 10,\n",
    "                'feature_noise_dim': 10, \n",
    "                'attribute_num_layers': 3, \n",
    "                'attribute_num_units': 100, \n",
    "                'feature_num_layers':  1, \n",
    "                'feature_num_units':100, \n",
    "                'use_attribute_discriminator': True, \n",
    "                'normalization': False, \n",
    "                'apply_feature_scaling': True, \n",
    "                'apply_example_scaling': True, \n",
    "                'binary_encoder_cutoff': 150, \n",
    "                'forget_bias': False, \n",
    "                'gradient_penalty_coef': 10.0, \n",
    "                'attribute_gradient_penalty_coef':10.0, \n",
    "                'attribute_loss_coef': 1.0, \n",
    "                'generator_learning_rate':  0.001, \n",
    "                'generator_beta1':  0.5, \n",
    "                'discriminator_learning_rate': 0.001, \n",
    "                'discriminator_beta1': 0.5, \n",
    "                'attribute_discriminator_learning_rate':  0.001, \n",
    "                'attribute_discriminator_beta1': 0.5, \n",
    "                'batch_size':  1024, \n",
    "                'discriminator_rounds': 1, \n",
    "                'generator_rounds': 1,\n",
    "                'mixed_precision_training': False}\n",
    "\n",
    "models = train_generator_per_label(split_data, DGAN_param, Experiment_param)\n",
    "generated_data,concatenated_data = generate_data_per_label(models, 20, DGAN_param, Experiment_param)\n",
    "label_to_int, int_to_label, concatenated_data['y'] = map_label_int(concatenated_data['y'])\n",
    "train_dataloader, validation_dataloader = create_data_loaders(concatenated_data['X'],concatenated_data['y'],n_splits=1, validation_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Host: localhost\n",
      "Database Port: 5432\n",
      "Log Level: INFO\n",
      "Max Retries: 5\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "def read_yaml_config(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        try:\n",
    "            config = yaml.safe_load(file)\n",
    "            return config\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "            return None\n",
    "\n",
    "config_path = 'config.yaml'\n",
    "config_data = read_yaml_config(config_path)\n",
    "\n",
    "if config_data:\n",
    "    print(\"Database Host:\", config_data['database']['host'])\n",
    "    print(\"Database Port:\", config_data['database']['port'])\n",
    "    print(\"Log Level:\", config_data['settings']['log_level'])\n",
    "    print(\"Max Retries:\", config_data['settings']['max_retries'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(np.unique(y))\n",
    "lr = 0.001\n",
    "best_acc = 0\n",
    "best_loss = np.inf\n",
    "model = GRU_Classifier(input_size=6, hidden_size=64, num_layers=2, num_classes=4)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "save_each_epoch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(np.unique(y))\n",
    "lr = 0.001\n",
    "best_acc = 0\n",
    "best_loss = np.inf\n",
    "model = LSTM_Classifier(num_layers=2,input_dim = 6,hidden_dim=64,output_dim=output_dim,dropout=0.3)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "save_each_epoch = True\n",
    "Experiment_param['model type'] = 'LSTM' # model type: LSTM, GRU, inception time, transformer\n",
    "run_param = {\"epochs\": 20,\n",
    "            \"patience\":5,\n",
    "            \"batch_size\": 20,\n",
    "            \"learning_rate\": lr, \n",
    "            \"criterion\":\"CrossEntropyLoss\",\n",
    "            \"optimizer\": \"Adam\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log(epochs,patience,train_dataloader,validation_dataloader,model,device,criterion,optimizer,save_each_epoch, run_param,Experiment_param):\n",
    "    run = neptune.init_run(\n",
    "    project=\"astarteam/FinalProject\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhMDI5YzIxMy00NjE1LTQ2MDUtOTk3NS1jNDJhMjIzZDE0NDMifQ==\",\n",
    ")  # your credentialscredentials\n",
    "\n",
    "    run[\"parameters\"] = run_param\n",
    "    Experiment_param['experiment state'] = 'pretraining'\n",
    "    run['Experiment_param'] = Experiment_param\n",
    "\n",
    "\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    # define the number of epochs and early stopping patience\n",
    "    for epoch in range(epochs):\n",
    "        #Train\n",
    "        train_loss, train_acc = train_loop(train_dataloader, model, device, criterion, optimizer)\n",
    "        run[\"train/accuracy\"].log(train_acc)\n",
    "        run[\"train/loss\"].log(train_loss)\n",
    "        #Evaluate\n",
    "        val_loss, val_acc = validation_loop(validation_dataloader, model, device, criterion)\n",
    "        run[\"validation/accuracy\"].log(val_acc)\n",
    "        run[\"validation/loss\"].log(val_loss)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "            if save_each_epoch:\n",
    "                torch.save(model.state_dict(),f'model_{epoch}.pt')\n",
    "        # otherwise, increment the early stopping counter\n",
    "        else:\n",
    "            early_stopping_counter += 1     \n",
    "        # if the early stopping counter has reached the patience, stop training\n",
    "        if early_stopping_counter == patience:\n",
    "            break\n",
    "    time.sleep(2)\n",
    "    print(\"Finished Training and validation, now uploading to Neptune.\")\n",
    "    run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_log(30,5,train_dataloader,validation_dataloader,model,device,criterion,optimizer,save_each_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int, int_to_label, y = map_label_int(y)\n",
    "og_train_dataloader, og_validation_dataloader = create_data_loaders(X,y,n_splits=1, validation_size=0.4)\n",
    "train_and_log(10,5,og_train_dataloader,og_validation_dataloader,model,device,criterion,optimizer,save_each_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular Training\n",
    "output_dim = len(np.unique(y))\n",
    "lr = 0.001\n",
    "best_acc = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_loss = np.inf\n",
    "model = LSTM_Classifier(num_layers=2,input_dim = 6,hidden_dim=64,output_dim=output_dim,dropout=0.3)\n",
    "model = model\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "save_each_epoch = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int, int_to_label, y = map_label_int(y)\n",
    "og_train_dataloader, og_validation_dataloader = create_data_loaders(X,y,n_splits=1, validation_size=0.4)\n",
    "train_and_log(25,25,og_train_dataloader,og_validation_dataloader,model,device,criterion,optimizer,save_each_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 100, 6)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine Tune\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset\\\\BasicMotions_TEST.ts', 'dataset\\\\BasicMotions_TRAIN.ts']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 100\n",
    "dataset_paths = glob.glob('dataset\\*.ts')\n",
    "\n",
    "for path in dataset_paths:\n",
    "    # read data\n",
    "    X,y = load_from_tsfile(path)\n",
    "    # expand dim\n",
    "    data = preprocess_dgan(X,sequence_length)\n",
    "    # Map the labels to integers\n",
    "    label_to_int, int_to_label, y_int = map_label_int(y)\n",
    "    # train data generator and create synthetic data\n",
    "    data_generator(X, y, train_size)\n",
    "    # create synthetic dataset\n",
    "    train_dataloader, validation_dataloader = create_dataset(X,y,n_splits, validation_size)\n",
    "    # train the model over syn\n",
    "    \n",
    "    create_dataset(X,y,n_splits, validation_size)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27c5c9eb550>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.title('Original Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.hist(X[y == 3][9,:,1:3])\n",
    "plt.legend(['X','Y','Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 3.,  6., 10., 38., 29.,  6.,  4.,  2.,  2.,  0.],\n",
       "        [ 0.,  0.,  2.,  4., 11., 47., 24.,  6.,  2.,  4.]]),\n",
       " array([-0.21081465, -0.09910052,  0.01261363,  0.12432777,  0.23604192,\n",
       "         0.34775606,  0.45947021,  0.57118434,  0.68289846,  0.79461265,\n",
       "         0.90632677]),\n",
       " <a list of 2 BarContainer objects>)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot synthetic data\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Synthetic Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.hist(concatenated_data['X'][concatenated_data['y'] == 3][100,:,1:3])\n",
    "# plt.plot(concatenated_data['X'][concatenated_data['y'] == 1][11,:,3])\n",
    "\n",
    "# plt.legend(['X','Y','Z'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinalVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31c4b883b398d3359910837fe640ccf591969e076e98c80af6519ee91f033179"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
